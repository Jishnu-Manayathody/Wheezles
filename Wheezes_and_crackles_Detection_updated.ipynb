{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing necessery libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1EdD0H785MO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "#import matplotlib.pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "#%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXnAeUB785MO",
        "outputId": "65026e96-7f27-4a23-c203-b9c2fd283060"
      },
      "outputs": [],
      "source": [
        "os.listdir(\"Respiratory_Sound_Database\\Respiratory_Sound_Database\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inside audio_and_txt_files folder corresponding to each .wav file there is a .txt file which has listed start time, end time of each breathing cycle in 0/1 showing if wheezhes or crackles are present in each of these cycles.\n",
        "\n",
        "Length of each .wav audio files are different so here we trim each audio into several smaller audio of length 5 seconds and label them based on if they have wheezles, crackles, both or none. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5gOXq4midU5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define your directory path containing the audio and text files\n",
        "directory_path = \"Respiratory_Sound_Database\\\\Respiratory_Sound_Database\\\\audio_and_txt_files\\\\\"\n",
        "filenames = [s.split('.')[0] for s in os.listdir(path = directory_path) if '.txt' in s]\n",
        "\n",
        "# Initialize a list to store data\n",
        "data = []\n",
        "\n",
        "# Process each file in the directory\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith('.wav'):\n",
        "        audio_path = os.path.join(directory_path, filename)\n",
        "        annotation_path = audio_path.replace('.wav', '.txt')\n",
        "\n",
        "        # Load the audio file\n",
        "        audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "        # Load the annotations\n",
        "        # Load the annotations with dtype specified\n",
        "        annotations = pd.read_csv(annotation_path, sep=\"\\t\", header=None,\n",
        "                                  names=['start', 'end', 'crackles', 'wheezes'],\n",
        "                                  dtype={'start': float, 'end': float, 'crackles': int, 'wheezes': int})\n",
        "\n",
        "\n",
        "        # Split the audio into 5-second segments and label them\n",
        "        for i in range(0, len(audio), 5000):  # 5000 ms = 5 seconds\n",
        "            segment = audio[i:i+5000]\n",
        "            segment_filename = f\"{filename[:-4]}_segment_{i//1000}.wav\"\n",
        "            segment_path = os.path.join(directory_path, 'segments', segment_filename)\n",
        "\n",
        "            # Ensure the segment directory exists\n",
        "            os.makedirs(os.path.join(directory_path, 'segments'), exist_ok=True)\n",
        "\n",
        "            # Export segment\n",
        "            segment.export(segment_path, format=\"wav\")\n",
        "\n",
        "            # Determine the label of the segment\n",
        "            segment_start = i / 1000.0\n",
        "            segment_end = (i + 5000) / 1000.0\n",
        "\n",
        "            # Filter annotations that overlap with the segment\n",
        "            relevant_annotations = annotations[(annotations['start'] < segment_end) & (annotations['end'] > segment_start)]\n",
        "\n",
        "            # Determine the label based on the annotations\n",
        "            has_crackles = any(relevant_annotations['crackles'] == 1)\n",
        "            has_wheezes = any(relevant_annotations['wheezes'] == 1)\n",
        "\n",
        "            if has_crackles and has_wheezes:\n",
        "                label = 'Both'\n",
        "            elif has_crackles:\n",
        "                label = 'Crackles'\n",
        "            elif has_wheezes:\n",
        "                label = 'Wheezes'\n",
        "            else:\n",
        "                label = 'None'\n",
        "\n",
        "            # Append to data list\n",
        "            data.append({'filename': segment_path, 'label': label})\n",
        "\n",
        "# Convert data to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwTZxyT2mmSv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
        "labels = to_categorical(df['label_encoded'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl3bU9WN1-ri",
        "outputId": "e17c0b78-37bc-4317-fcb1-724609c2997d"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path):\n",
        "    try:\n",
        "        # Ensure the file exists to avoid FileNotFoundError\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File does not exist: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
        "\n",
        "        # Correctly extract the segment index from the filename\n",
        "        # This accounts for filenames with multiple underscores before \"segment\"\n",
        "        try:\n",
        "            base_name = os.path.basename(file_path)  # Isolate the filename from the path\n",
        "            segment_index = int(base_name.split('_segment_')[-1].split('.')[0])\n",
        "        except ValueError as e:\n",
        "            print(f\"Error parsing segment index from filename: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        # No need to adjust for segment start time, since we load individual segment files\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while parsing file: {file_path}, Error: {e}\")\n",
        "        mfccs_processed = None\n",
        "\n",
        "    return mfccs_processed\n",
        "\n",
        "# Assuming `df` contains a 'filename' column with the full path to each audio segment\n",
        "df['features'] = df['filename'].apply(lambda x: extract_features(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzxP7m921-dN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Ensure features are in a numpy array form suitable for training\n",
        "features = np.array(df['features'].tolist())\n",
        "features = np.expand_dims(features, axis=2)  # Reshape for CNN input\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aht3VcIlhcr-",
        "outputId": "01ab54d6-3c65-4c2d-f7dd-42224b25564d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "input_shape = (X_train.shape[1], 1, 1)  \n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Conv2D(64, (3, 1), activation='relu', input_shape=input_shape, padding='same'),\n",
        "    Conv2D(64, (3, 1), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 1), activation='relu', padding='same'),\n",
        "    Conv2D(128, (3, 1), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, (3, 1), activation='relu', padding='same'),\n",
        "    Conv2D(256, (3, 1), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 1)),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(np.unique(df['label_encoded'])), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rubloxZwk20z",
        "outputId": "be9a4d2f-9196-4d75-eff6-48726ce44074"
      },
      "outputs": [],
      "source": [
        "# Use the trained model to make predictions on test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Display the predicted labels\n",
        "print(\"Predicted Labels:\", predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD2pFrAmlD43",
        "outputId": "f5a34bb7-cdb4-4ed1-d1fe-2fd793d33706"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(true_labels, predicted_labels, target_names=['none', 'crackles', 'wheezes', 'both']))\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoKeUOIG85Ma"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
